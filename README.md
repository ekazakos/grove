# ğŸš€ Large-scale Pre-training for Grounded Video Caption Generation

**Evangelos Kazakos<sup>1</sup>, Cordelia Schmid<sup>2</sup>, Josef Sivic<sup>1</sup>**  
<sup>1</sup>Czech Institute of Informatics, Robotics and Cybernetics at the Czech Technical University in Prague  
<sup>2</sup>Inria, Ã‰cole normale supÃ©rieure, CNRS, PSL Research University

ğŸ“„ [**arXiv**](https://arxiv.org/abs/2503.10781) | ğŸŒ [**Project Website**](https://ekazakos.github.io/grounded_video_caption_generation/)

![Project Banner](teaser.png)

### ğŸ“¢ News
- ğŸ”¥ **25/06/2025**: Paper accepted to **ICCV 2025** ğŸ‰

**Data, Code, and Models - Coming Soon!** â³  

We are working hard to release the datasets, source code, and pre-trained models. Stay tuned!  

ğŸ“Œ **What's Coming?**  
- ğŸ“‚ **Data**: (i) Large-scale automatically annotated pre-training dataset for Grounded Video Caption Generation, (ii) Small-scale, high-quality human-labelled dataset for fine-tuning and evaluation.  
- ğŸ–¥ï¸ **Code**: Training, evaluation, and inference scripts.
- ğŸ‹ï¸ **Models**: Pre-trained checkpoints for reproduction. 

Stay updated by â­ starring this repo and watching for updates!

ğŸ“¬ For inquiries or collaborations, feel free to reach out.

---

ğŸ“– **BibTeX**
```bibtex
@article{kazakos2025grove,
  title={Large-scale Pre-training for Grounded Video Caption Generation},
  author={Evangelos Kazakos and Cordelia Schmid and Josef Sivic},
  journal={arXiv preprint arXiv:2503.10781},
  year={2025}
}
