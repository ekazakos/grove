# 🚀 Large-scale Pre-training for Grounded Video Caption Generation

**Evangelos Kazakos<sup>1</sup>, Cordelia Schmid<sup>2</sup>, Josef Sivic<sup>1</sup>**  
<sup>1</sup>Czech Institute of Informatics, Robotics and Cybernetics at the Czech Technical University in Prague  
<sup>2</sup>Inria, École normale supérieure, CNRS, PSL Research University

📄 [**arXiv**](https://arxiv.org/abs/2503.10781) | 🌐 [**Project Website**](https://ekazakos.github.io/grounded_video_caption_generation/)

![Project Banner](teaser.png)

### 📢 News
- 🔥 **25/06/2025**: Paper accepted to **ICCV 2025** 🎉

**Data, Code, and Models - Coming Soon!** ⏳  

We are working hard to release the datasets, source code, and pre-trained models. Stay tuned!  

📌 **What's Coming?**  
- 📂 **Data**: (i) Large-scale automatically annotated pre-training dataset for Grounded Video Caption Generation, (ii) Small-scale, high-quality human-labelled dataset for fine-tuning and evaluation.  
- 🖥️ **Code**: Training, evaluation, and inference scripts.
- 🏋️ **Models**: Pre-trained checkpoints for reproduction. 

Stay updated by ⭐ starring this repo and watching for updates!

📬 For inquiries or collaborations, feel free to reach out.

---

📖 **BibTeX**
```bibtex
@article{kazakos2025grove,
  title={Large-scale Pre-training for Grounded Video Caption Generation},
  author={Evangelos Kazakos and Cordelia Schmid and Josef Sivic},
  journal={arXiv preprint arXiv:2503.10781},
  year={2025}
}
